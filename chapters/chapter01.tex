The development of persistence\index{persistence} theory\index{persistence theory} in topological data analysis\index{topological data analysis}\index{topological data analysis} (TDA\index{TDA}) marks a significant advancement in the quantitative analysis of complex, high-dimensional data sets. Conventional statistical methods frequently prove inadequate for capturing the intricate geometric and topological structure\index{topological structure}s\index{topological structure} of such data, particularly when these are obscured by noise or nonlinear relationships.

Persistence\index{persistence} theory, and in particular persistent homology\index{homology}\index{homology}, provides a rigorous mathematical framework for the systematic identification and quantification of topologically relevant structures at varying levels of detail. Persistent homology\index{homology}\index{homology} is a mathematical concept that is employed for the analysis of homological features\index{homological features}\index{homological features} in data. These representations permit a precise description of the data structure and enable the distinction between significant features and noise. The persistent homology\index{homology} techniques are founded upon the principles of algebraic topology\index{algebraic topology}\index{algebraic topology}, wherein homology\index{homology} groups serve as algebraic invariants for the classification of topological spaces\index{topological spaces}\index{topological spaces}. In persistent homology\index{homology}, this concept is extended to a filtration\index{filtration} where a real-valued function\index{real-valued function} serves as the parameter of a nested sequence of topological spaces\index{topological spaces}. The characteristics of this filtration are captured in persistence\index{persistence} intervals\index{persistence intervals}, which indicate the degree of robustness associated with the features in question. The persistent homology\index{homology} is obtained by constructing simplicial complex\index{simplicial complex}es\index{simplicial complex}\index{simplicial complex} from the data through the efficient application of computational methods. In addition to their descriptive function, persistence\index{persistence} diagrams\index{persistence diagrams} and barcodes\index{persistence barcodes} can be integrated into statistical and machine learning\index{machine learning}\index{machine learning} methods, enabling quantitative comparisons between data sets -- as an example consider the work of Melodia et al. \cite{melodia2020persistent,melodia2021estimate,melodia2021homological}.

The theory of persistence\index{persistence}\index{persistence} is a valuable tool in TDA\index{TDA}\index{topological data analysis}, as it remains stable in the analysis of data that has been subject to perturbations. This theory guarantees that minor alterations to the input data will only result in slight alterations to the persistence\index{persistence} diagrams\index{persistence diagrams}, thereby confirming the reliability of the topological features\index{topological features}\index{topological features} that have been extracted. This robustness is particularly beneficial when analysing data that is noisy or incomplete. Persistence\index{persistence} theory\index{persistence theory} serves to bridge the gap between abstract mathematical theory and the more practical field of data analysis. It has thus become a fundamental tool in this field.

\section{History}
The growth of persistence\index{persistence} theory\index{persistence theory} in TDA\index{TDA}\index{TDA} has been shaped by the seminal contributions of pioneering researchers, who have collectively established persistence\index{persistence} as a core instrument for grasping the topological aspects of data.

\textbf{The field of size theory:} The origins of persistence\index{persistence} theory can be traced back to the end of the 20th century, with the work of Patrizio Frosini and Massimo Ferri at the University of Bologna. Their research in set theory focused on the natural pseudodistance between functions defined on homeomorphic topological spaces\index{topological spaces}\index{topological spaces} \cite{Frosini1999,Ferri1998}. In particular, size theory, as applied to $0$-dimensional homology\index{homology}\index{0-dimensional homology}, provided a framework for quantifying differences between topological spaces\index{topological spaces}, and introduced a method for capturing persisting features across scales.

\textbf{Fractal geometry\index{fractal geometry}:} During her doctoral research at the University of Colorado Boulder, Vanessa Robins extended the application of persistence\index{persistence} theory to fractal geometry\index{fractal geometry}\index{fractal geometry}. By means of alpha forms\index{alpha forms}\index{alpha forms} -- a concept first proposed by Herbert Edelsbrunner et al. -- Robins provided evidence of the efficacy of persistent homology\index{homology} in capturing the multiscale structure of fractal sets\index{fractal sets}\index{fractal sets} \cite{Robins2000, Edelsbrunner1994}.

\textbf{Algebraic foundations:} Herbert Edelsbrunner and his team at Duke University have made significant progress in formalising the algebra of persistence\index{persistence} theory\index{persistence theory}. They introduced fundamental concepts, including simplicial filtrations, which systematically construct topological spaces\index{topological spaces} from data points by adding simplices in a hierarchical manner \cite{Edelsbrunner2000}. This filtration process tracks topological features\index{topological features}, such as connected components, loops and voids, across different scales, leading to the birth and death of these features. The distinction between positive and negative simplices, introduced by Edelsbrunner's group, is crucial for understanding the emergence and decay of homological features\index{homological features} within a filtration of point clouds. 

\section{Computational Aspects}
The computational efficiency of persistence\index{persistence} theory\index{persistence theory} has been a significant factor in its extensive adoption across a range of scientific disciplines. This efficiency, underpinned by robust algorithmic principles, has established persistence\index{persistence} theory as a key analytical tool for complex data sets.

\textbf{Algorithmic developments:} The algorithms for computing persistent homology\index{computing persistent homology}\index{homology}\index{computing persistent homology}, developed by Herbert Edelsbrunner and colleagues, are founded upon rigorous mathematical theory and optimised for practical application. These algorithms entail the construction and reduction of boundary matrices for the efficient computation of homology\index{homology} groups\index{homology groups} across a filtration of simplicial complex\index{simplicial complex}es\index{simplicial complex}\index{simplicial complex}. Among these algorithms, the matrix reduction algorithm plays a pivotal role in the computation of persistence\index{persistence} intervals\index{persistence intervals}. The practical implementation of these algorithms has led to the development of standard software packages, including \texttt{GUDHI}, \texttt{Ripser}, and \texttt{Dionysus} \cite{Otter2017}.

\textbf{Applications in life sciences:} In the field of life sciences, persistent homology\index{homology}\index{homology} has emerged as a powerful tool for the study of the structure and function of biological molecules, particularly proteins. Proteins are complex macromolecules, the function of which is intricately linked to their three-dimensional structure. Persistent homology\index{homology}\index{homology} is a method for identifying patterns within a protein's structure that persist across different scales. These patterns frequently correspond to critical functional regions, such as binding pockets or active centers, and provide insights into protein interactions and stability under diverse conditions \cite{Kovacev-Nikolic2016}. In the field of neuroscience, persistence\index{persistence} theory has been employed to examine brain networks, thereby providing a novel methodology for analysing the intricate connectivity patterns that underpin brain function. By constructing simplicial complex\index{simplicial complex}es\index{simplicial complex}\index{simplicial complex} from neural data, researchers utilise persistent homology\index{homology}\index{homology}  to monitor alterations in brain region connectivity over time. This approach has yielded new insights into the manner in which brain networks reorganise during cognitive processes or in response to neurological diseases \cite{Giusti2016, unger2023simplex}.

\textbf{Applications in machine learning\index{machine learning}:} In the field of machine learning\index{machine learning}, persistent homology\index{homology} is a valuable tool for uncovering the underlying topological structure\index{topological structure} of data distributions. This allows for the effective completion of tasks such as clustering, classification, and anomaly detection. The topological features\index{topological features} of data provide essential insights into the organisation of the data space. For example, persistent homology\index{homology} can identify clusters of data points that form distinct topological features\index{topological features}, such as loops or voids, which correspond to different classes or subpopulations within the data set. This has been demonstrated in studies referenced in the literature \cite{Hofer2017,melodia2020persistent,melodia2021estimate,melodia2021homological}. The incorporation of topological data into machine learning\index{machine learning} models improves their resilience and generalisation capabilities, particularly in the context of noisy or incomplete data.

\textbf{Robustness to noise:} A defining feature of persistence\index{persistence} theory\index{persistence theory} is its resilience to noise, which represents a substantial advantage in the context of real-world data analysis. Persistence\index{persistence} theory is concerned with the topological features\index{topological features} that remain consistent across different scales, thereby filtering out noise-induced artefacts. Robustness is grounded in the stability theorem\index{stability theorem}s\index{stability theorem}, which guarantee that minor changes are induced in persistence\index{persistence} by small perturbations of the data \cite[\S 3.1]{Cohen-Steiner2007}.

\section{Advanced Extensions}
The adaptability and extensibility of persistence\index{persistence} theory are exemplified by its sophisticated developments. Among these extensions, discrete morse theory\index{discrete morse theory}\index{discrete morse theory}, multiparameter persistence\index{multiparameter persistence}\index{persistence}\index{multiparameter persistence}, and zigzag persistence\index{zigzag persistence}\index{persistence}\index{zigzag persistence} represent notable ones.

\textbf{Discrete morse theory\index{discrete morse theory}:} The discrete morse theory\index{discrete morse theory}, initially proposed by Robin Forman, represents an extension of the classical morse theory\index{classical morse theory}\index{classical morse theory} to discrete spaces\index{discrete spaces}\index{discrete spaces}, such as simplicial complex\index{simplicial complex}es\index{simplicial complex}. This extension is of particular value in TDA\index{TDA}, as it facilitates the simplification of complex spaces while ensuring the preservation of essential topological characteristics. The construction of discrete Morse functions on simplicial complex\index{simplicial complex}es\index{simplicial complex} enables the reduction of the number of critical simplices\index{critical simplex}, thereby facilitating more efficient persistent homology\index{homology} computations \cite{Forman2002}. The critical simplices correspond to significant topological features\index{topological features}, and focusing on these reduces the computational complexity of calculating persistence\index{persistence} intervals\index{persistence intervals}. This approach is especially advantageous in large data sets, where the number of simplices can render traditional homology\index{homology} computations impractical.

\textbf{Multiparameter persistence\index{multiparameter persistence}\index{persistence}:} Multiparameter persistence\index{multiparameter persistence}\index{persistence} represents an extension of the traditional single-parameter filtration approach, whereby filtrations are considered that are indexed by multiple parameters simultaneously. This allows for a more comprehensive examination of topological characteristics, as distinct parameters facilitate the capture of diverse aspects of the data's structural elements. To illustrate, one might filter a data set by both scale and density, thereby uncovering topological features\index{topological features} that would otherwise remain invisible under a one-parameter filtration \cite{CarlssonZomorodian2009}. The use of multiple parameters results in a more complex algebraic structure, which in turn gives rise to computational and visualisation challenges associated with multiparameter persistence\index{multiparameter persistence}\index{persistence} modules. In contrast to single-parameter persistence\index{persistence}, where persistence\index{persistence} diagrams or barcodes offer a comprehensive invariant, multiparameter persistence\index{multiparameter persistence}\index{persistence} lacks a straightforward representation. In contrast, more complex invariants, such as generalized persistence\index{persistence} diagrams\index{generalized persistence\index{persistence} diagrams} or rank invariants\index{rank invariants}\index{rank invariants}, are used to capture relationships between parameters.

\textbf{Zigzag persistence\index{zigzag persistence}\index{persistence}:} Zigzag persistence\index{zigzag persistence}\index{persistence} represents an extension of the traditional persistent homology\index{homology} framework to allow for the analysis of dynamic data sets, whereby the data may undergo change over time. In contrast to the standard persistence\index{persistence} approach, which requires a monotonically increasing sequence of spaces, zigzag persistence\index{zigzag persistence}\index{persistence} permits both forward and backward inclusions throughout the filtration process \cite{Carlsson2010}. This flexibility permits the analysis of topological features\index{topological features} in settings where data is not static, such as time-varying networks or data sets undergoing changes due to external factors. Zigzag persistence\index{zigzag persistence}\index{persistence} is a methodology that captures the evolution of topological features\index{topological features}, including their appearance, disappearance, and reappearance as the data changes. The algebraic structure underlying zigzag persistence\index{zigzag persistence}\index{persistence} is more intricate than that of standard persistence\index{persistence}. It involves directed graphs and a more complex form of homological algebra.

\section{Contribution}
This work presents a comprehensive summary of persistent homology\index{homology} theory, harmonising various proofs to provide a unified examination of persistence\index{persistence} modules and persistent (co)homology\index{homology}\index{persistent cohomology} from an algebraic-topological perspective. The objective of this study is to provide a mathematically rigorous explanation for the remarkable success of persistent homology\index{homology} in data analytics. Our approach is based on the assumption that real-world data can be represented on a triangulable topological space and that simplicial structures allow us to derive invariants of this space. We provide a rigorous proof of the merits of this approach and demonstrate its clear and well-defined foundations. Moreover, we shed light on the interplay between relative and absolute (co)homology\index{cohomology} on persistence\index{persistence} intervals and fill some gaps within the literature.