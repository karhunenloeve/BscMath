The development of persistence theory\index{persistence theory} in topological data analysis\index{topological data analysis} (TDA) marks a significant advance in the quantitative analysis of complex, high-dimensional data sets. Conventional statistical methods frequently prove inadequate for capturing the intricate geometric and topological structures\index{topological structure} of such data, particularly when these are obscured by noise or nonlinear relationships. Persistence theory, and in particular persistent homology\index{persistent homology}\index{homology}, provides a rigorous mathematical framework for the systematic identification and quantification of topologically relevant structures at varying levels of detail. Persistent homology\index{homology} is a mathematical concept that is employed for the analysis of homological features\index{homological features} in data. These representations permit a precise description of the data structure and enable the distinction between significant features and noise. The persistent homology techniques are founded upon the principles of algebraic topology\index{algebraic topology}, wherein homology groups serve as algebraic invariants for the classification of topological spaces\index{topological spaces}. In persistent homology\index{persistent homology}, this concept is extended to a filtration\text{filtration} where a real-valued function\index{real-valued function} serves as the parameter of a nested sequence of topological spaces. The characteristics of this filtration are captured in persistence intervals\index{persistence intervals}, which indicate the degree of robustness associated with the features in question. The persistent homology is obtained by constructing simplicial complexes\index{simplicial complexes} from the data through the efficient application of computational methods. In addition to their descriptive function, persistence diagrams\index{persistence diagrams} and barcodes\index{persistence barcodes} can be integrated into statistical and machine learning\index{machine learning} methods, enabling quantitative comparisons between data sets. This approach has been employed in a number of studies, including those referenced in Melodia et al. \cite{melodia2018deep,melodia2020persistent,melodia2021estimate,melodia2021homological}.

The theory of persistence\index{persistence} is a valuable tool in TDA\index{topological data analysis}, as it remains stable in the analysis of data that has been subject to perturbations. This theory guarantees that minor alterations to the input data will only result in slight alterations to the persistence diagrams\index{persistence diagrams}, thereby confirming the reliability of the topological features\index{topological features} that have been extracted. This robustness is particularly beneficial when analysing data that is noisy or incomplete. Persistence theory\index{persistence theory} serves to bridge the gap between abstract mathematical theory and the more practical field of data analysis. It has thus become a fundamental tool in this field.

\section{History}
The growth of persistence theory\index{persistence theory} in TDA\index{TDA} has been shaped by the seminal contributions of pioneering researchers, who have collectively established persistence as a core instrument for grasping the topological aspects of data.

\textbf{The field of size theory:} The origins of persistence theory can be traced back to the end of the 20th century, with the work of Patrizio Frosini and Massimo Ferri at the University of Bologna. Their research in set theory focused on the natural pseudodistance between functions defined on homeomorphic topological spaces\index{topological spaces} \cite{Frosini1999,Ferri1998}. In particular, size theory, as applied to $0$-dimensional homology\index{0-dimensional homology}, provided a framework for quantifying differences between topological spaces, and introduced a method for capturing persisting features across scales.

\textbf{Fractal geometry:} During her doctoral research at the University of Colorado Boulder, Vanessa Robins extended the application of persistence theory to fractal geometry\index{fractal geometry}. By means of alpha forms\index{alpha forms} -- a concept first proposed by Herbert Edelsbrunner et al. -- Robins provided evidence of the efficacy of persistent homology\index{persistent homology} in capturing the multiscale structure of fractal sets\index{fractal sets} \cite{Robins2000, Edelsbrunner1994}.

\paragraph*{Algebraic Foundations}
Herbert Edelsbrunner and his team at Duke University made significant progress in formalising the algebra of persistence theory\index{persistence theory} \cite{Edelsbrunner2000}. They introduced key concepts such as simplicial filtrations, which systematically construct topological spaces from data points by adding simplices in a hierarchical fashion. This filtration process tracks topological features -- such as connected components, loops and voids -- across different scales, leading to the birth and death of these features. The distinction between positive and negative simplices, introduced by Edelsbrunner's group, is crucial for understanding the emergence and decay of homological features\index{homological features} within a point cloud. 

\section{Computational Aspects}
The computational efficiency of persistence theory\index{persistence theory} has been crucial to its widespread adoption in various scientific domains. This efficiency, based on robust algorithmic foundations, has established persistence theory\index{persistence theory} as an essential tool for analysing complex datasets.

\paragraph*{Algorithmic Developments}
The algorithms for computing persistent homology\index{persistent homology}\index{homology}, developed by Herbert Edelsbrunner and colleagues, are founded upon rigorous mathematical theory and optimized for practical application. These algorithms entail the construction and reduction of boundary matrices for the efficient computation of homology\index{homology} groups across a filtration of simplicial complex\index{simplicial complex}es. Among these algorithms, the matrix reduction algorithm plays a pivotal role in the computation of persistence intervals. The practical implementation of these algorithms has led to the development of standard software packages, including GUDHI, Ripser, and Dionysus \cite{Otter2017}.

\paragraph*{Applications in Life Sciences}
In the field of life sciences, persistent homology\index{persistent homology}\index{homology} has emerged as a powerful tool for the study of the structure and function of biological molecules, particularly proteins. Proteins are complex macromolecules whose function is intricately linked to their three-dimensional structure. Persistent homology\index{homology} is a method for identifying patterns, within a protein's structure that persist across different scales. These patterns frequently correspond to critical functional sites, such as binding pockets or active sites, and provide insights into protein interactions and stability under diverse conditions \cite{Kovacev-Nikolic2016}. In the field of neuroscience, persistence theory\index{persistence theory} has been employed to examine brain networks, providing a novel methodology for analysing the intricate connectivity patterns that underpin brain function. By constructing simplicial complex\index{simplicial complex}es from neural data, researchers employ persistent homology\index{persistent homology}\index{homology} to monitor alterations in brain region connectivity over time. This approach has yielded new insights into the manner in which brain networks reorganise during cognitive processes or in response to neurological diseases \cite{Giusti2016}. In the field of machine learning, persistent homology\index{persistent homology}\index{homology} is a valuable tool for uncovering the underlying topological structure\index{topological structure} of data distributions. This enables the effective performance of tasks such as clustering, classification, and anomaly detection. The topological features of data provide crucial insights into the organisation of the data space. For instance, persistent homology\index{persistent homology}\index{homology} can detect clusters of data points that form distinct topological features, such as loops or voids, which correspond to different classes or subpopulations within the data \cite{Hofer2017,melodia2018deep,melodia2020persistent,melodia2021estimate,melodia2021homological}. The integration of topological information into machine learning models enhances their robustness and generalisation, particularly in the presence of noise or incomplete data.

\paragraph*{Robustness to Noise}
A defining feature of persistence theory\index{persistence theory} is its resilience to noise, which represents a substantial advantage in the context of real-world data analysis. Persistence theory is concerned with the topological features that remain consistent across different scales, thereby filtering out noise-induced artefacts. This robustness is mathematically grounded in stability theorems, which guarantee that minor changes are induced in the persistence diagram by small perturbations in the input data \cite{Cohen-Steiner2007}.

\section{Advanced Extensions}
The adaptability and extensibility of persistence theory\index{persistence theory} are exemplified by its sophisticated developments, which expand its applicability to more intricate mathematical and data analysis problems. Among these extensions, discrete Morse theory, multiparameter persistence, and zigzag persistence represent notable advancements, each addressing particular challenges and broadening the scope of TDA.

\paragraph*{Discrete Morse Theory}
The discrete Morse theory, as first proposed by Robin Forman, represents an extension of the classical Morse theory to discrete spaces, such as simplicial complex\index{simplicial complex}es. This extension is of particular value in TDA, as it facilitates the simplification of complex spaces while ensuring the preservation of essential topological characteristics. The construction of discrete Morse functions on simplicial complex\index{simplicial complex}es allows for the reduction of the number of critical simplices, thereby facilitating more efficient persistent homology\index{persistent homology}\index{homology} computations \cite{Forman2002}. The critical simplices correspond to significant topological features, and focusing on these reduces the computational complexity of calculating persistence intervals. This approach is especially advantageous in large datasets, where the number of simplices can render traditional homology\index{homology} computations impractical.

\paragraph*{Multiparameter Persistence}
Multiparameter persistence represents an extension of the traditional single-parameter filtration approach, whereby filtrations are considered that are indexed by multiple parameters simultaneously. This enables a more comprehensive examination of topological characteristics, as distinct parameters facilitate the capture of diverse aspects of the data's structural elements. To illustrate, one might filter a dataset by both scale and density, thereby uncovering topological features that would otherwise remain invisible under a $1$-parameter filtration \cite{CarlssonZomorodian2009}. The employment of multiple parameters gives rise to a more intricate algebraic structure, thereby presenting computational and visualisation challenges associated with multiparameter persistence modules. In contrast to single-parameter persistence, where persistence diagrams\index{persistence diagrams} or barcodes\index{barcodes} offer a comprehensive invariant, multiparameter persistence lacks a straightforward representation. Instead, more complex invariants, such as generalized persistence diagrams\index{persistence diagrams} or rank invariants, capture the intricate relationships between parameters.

\paragraph*{Zigzag Persistence}
Zigzag persistence represents an extension of the traditional persistent homology\index{persistent homology}\index{homology} framework to accommodate dynamic datasets, wherein the data may undergo change over time or under varying conditions. In contrast to the standard persistence approach, which necessitates a monotonically increasing sequence of spaces, zigzag persistence permits both forward and backward inclusions throughout the filtration \cite{Carlsson2010}. This flexibility allows for the analysis of topological features in settings where data is not static, such as time-varying networks or datasets undergoing changes due to external factors. Zigzag persistence captures the evolution of topological features, including their appearance, disappearance, and reappearance as the data changes, providing a more accurate and comprehensive analysis of dynamic systems. The algebraic structure underlying zigzag persistence is more intricate than that of standard persistence, involving directed graphs and more complex homological algebra.

\section{Our Contribution}
This work presents a comprehensive summary of persistent homology\index{persistent homology}\index{homology} theory, unifying various proofs to facilitate a unified examination of persistence modules, persistent (co)homology\index{homology}, and zigzag persistence from an algebraic-topological perspective.The objective of this study is to provide a mathematically precise explanation for the remarkable success of persistent homology\index{persistent homology}\index{homology} in data analytics. Our approach is based on the assumption that real-world data resides on a triangulable topological space and that simplicial structures allow us to derive invariants of this space. We rigorously prove the validity of this approach and demonstrate that it is well-defined. Furthermore, we elucidate the interaction between cohomology\index{homology} and zigzag persistence on persistence intervals, addressing and resolving non-trivial gaps previously left open in the literature.